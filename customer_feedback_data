import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import numpy as np

# Load the dataset
df = pd.read_csv("/Users/gillianmondero/Downloads/Customer_Feedback_Data.csv")
print("Initial Dataset Structure:\n", df.head())
print("\nDataset Info:")
df.info()

# Remove duplicates
duplicates = df[df.duplicated()]
print(f"\nNumber of duplicate rows: {duplicates.shape[0]}")
df = df.drop_duplicates()
print(f"Shape after removing duplicates: {df.shape}")

# Handle missing values
missing_values = df.isnull().sum()
print("Missing values in each column:\n", missing_values)
df['Satisfaction_Score'] = df['Satisfaction_Score'].fillna(df['Satisfaction_Score'].median())
print("Missing values in Satisfaction_Score column after imputation:", df['Satisfaction_Score'].isnull().sum())

# Convert categorical features to numerical
df['Feedback_Comments'] = df['Feedback_Comments'].astype('category')
df['Feedback_Comments_Encoded'] = df['Feedback_Comments'].cat.codes
print("Original and Encoded Feedback_Comments:\n", df[['Feedback_Comments', 'Feedback_Comments_Encoded']].head())

# Define a function to detect outliers using the IQR method
def detect_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
    return outliers

# Detect outliers in Satisfaction_Score and Likelihood_to_Recommend
satisfaction_outliers = detect_outliers_iqr(df, 'Satisfaction_Score')
recommendation_outliers = detect_outliers_iqr(df, 'Likelihood_to_Recommend')
print("Number of Satisfaction_Score outliers:", satisfaction_outliers.shape[0])
print("Number of Likelihood_to_Recommend outliers:", recommendation_outliers.shape[0])

# Handle outliers by mean imputation
mean_satisfaction = df['Satisfaction_Score'].mean()
df.loc[satisfaction_outliers.index, 'Satisfaction_Score'] = mean_satisfaction

mean_recommend = df['Likelihood_to_Recommend'].mean()
df.loc[recommendation_outliers.index, 'Likelihood_to_Recommend'] = mean_recommend

# Normalize numerical columns using MinMaxScaler
scaler = MinMaxScaler()
numerical_columns = ['Satisfaction_Score', 'Likelihood_to_Recommend']
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])
print("Normalized Numerical Columns:\n", df[numerical_columns].head())

# Categorize Likelihood_to_Recommend
df['Recommendation_Category'] = pd.cut(
    df['Likelihood_to_Recommend'], 
    bins=[0, 4, 7, 10], 
    labels=['Low', 'Medium', 'High'], 
    right=True
)

# Categorize Satisfaction_Score
df['Satisfaction_Category'] = pd.cut(
    df['Satisfaction_Score'], 
    bins=[0, 3, 6, 10], 
    labels=['Dissatisfied', 'Neutral', 'Satisfied'], 
    right=True
)

# Display the updated dataset
print("Updated Dataset with Engineered Features:\n", df.head())

# Summary of the dataset
print("Dataset Summary:\n", df.describe())
print("\nUnique values per column:\n", df.nunique())

# Save file
df.to_csv("cleaned_customer_feedback_data.csv", index=False)
